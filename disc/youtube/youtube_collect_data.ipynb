{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to automate collection of YouTube data for DiSC lessons\n",
    "\n",
    "This script uses the YouTube API to download viewing stats (an alternative to manual downloading using the YouTube Studio Analytics), then uses the GitHub API to update CSV files archiving the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, configuration, functions, etc.\n",
    "\n",
    "# Notes: you will have to use PIP to install the GitHub and Google SDKs before these import statements will work\n",
    "# The YouTube API is part of the family of Google APIs and uses Google's generic SDK\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from time import sleep\n",
    "import csv\n",
    "import io\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from github import Github # GitHub SDK\n",
    "\n",
    "# Google API SDKs:\n",
    "import google.oauth2.credentials\n",
    "import google_auth_oauthlib.flow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "accept_media_type = 'application/json' # Not sure if I actually use this anywhere\n",
    "\n",
    "# Set configuration details necessary for interacting with the GitHub API\n",
    "\n",
    "# the access token should be generated for read/write access to public repos\n",
    "# see https://developer.github.com/v3/auth/#working-with-two-factor-authentication\n",
    "# see https://github.com/settings/tokens/new\n",
    "# select public_repo\n",
    "\n",
    "# reference on PyGithub: https://pygithub.readthedocs.io/en/latest/github_objects/Repository.html\n",
    "# reference on GitHub API: https://developer.github.com/v3/guides/getting-started/\n",
    "\n",
    "github_username = ''  # set to empty string if using a token (for 2FA)\n",
    "organization_name = 'heardlibrary'\n",
    "organization_is_user = False\n",
    "repo_name = 'dashboard'\n",
    "cred_directory = 'home' # set to 'home' if the credential is in the home directory, otherwise working directory\n",
    "path_to_directory = 'disc/youtube/'\n",
    "\n",
    "# Set configuration details necessary for interacting with the YouTube Analytics API\n",
    "scopes = ['https://www.googleapis.com/auth/yt-analytics.readonly']\n",
    "# Disable OAuthlib's HTTPs verification when running locally.\n",
    "# *DO NOT* leave this option enabled when running in production.\n",
    "os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "api_service_name = 'youtubeAnalytics'\n",
    "api_version = 'v2'\n",
    "# You will need to modify this line according to how you named your secrets file and where you put it on your drive.\n",
    "# Do NOT store the file within the path of a GitHub repo since you don't want to expose it publicly!!!\n",
    "client_secrets_filename = 'client_secret_youtube_analytics_download.json'\n",
    "if cred_directory == 'home':\n",
    "    home = str(Path.home()) #gets path to home directory; supposed to work for Win and Mac\n",
    "    client_secrets_file = home + '/' + client_secrets_filename\n",
    "else:\n",
    "    cred_directory = 'working'\n",
    "    client_secrets_file = client_secrets_filename\n",
    "\n",
    "# -----------------\n",
    "# utility functions\n",
    "# -----------------\n",
    "\n",
    "# NOTE: change the user_agent_header string to something appropriate for your project\n",
    "# Sending a user-agent header is necessary for public Wikidata endpoints, but probably not needed here\n",
    "# since particular API credentials are needed for the GitHub and YouTube APIs\n",
    "def generate_header_dictionary(accept_media_type):\n",
    "    user_agent_header = 'VanderDataBot/0.1 (https://github.com/HeardLibrary/linked-data/tree/master/publications/data; mailto:steve.baskauf@vanderbilt.edu)'\n",
    "    request_header_dictionary = {\n",
    "        'Accept' : accept_media_type,\n",
    "        'User-Agent': user_agent_header\n",
    "    }\n",
    "    return request_header_dictionary\n",
    "\n",
    "def generate_utc_date():\n",
    "    whole_time_string_z = datetime.datetime.utcnow().isoformat() # form: 2019-12-05T15:35:04.959311\n",
    "    date_z = whole_time_string_z.split('T')[0] # form 2019-12-05\n",
    "    return date_z\n",
    "\n",
    "# RAW FILE FUNCTIONS\n",
    "\n",
    "# read raw string from a file in GitHub\n",
    "def read_string_from_github_file(organization_name, repo_name, path_to_directory, filename):\n",
    "    path = path_to_directory + filename\n",
    "    r = requests.get('https://raw.githubusercontent.com/' + organization_name + '/' + repo_name + '/master/' + path)\n",
    "    return r.text\n",
    "\n",
    "# LIST OF DICTIONARIES FUNCTIONS\n",
    "\n",
    "# read from a CSV file on disk into a list of dictionaries (representing a table)\n",
    "def read_dicts_from_csv(filename):\n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as file_object:\n",
    "        dict_object = csv.DictReader(file_object)\n",
    "        table = []\n",
    "        for row in dict_object:\n",
    "            table.append(row)\n",
    "    return table\n",
    "\n",
    "# write a list of dictionaries to a CSV file on disk\n",
    "def write_dicts_to_csv(table, filename, fieldnames):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csv_file_object:\n",
    "        writer = csv.DictWriter(csv_file_object, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# read from a CSV file in GitHub into a list of dictionaries (representing a table)\n",
    "def read_dicts_from_github_csv(organization_name, repo_name, path_to_directory, filename):\n",
    "    path = path_to_directory + filename\n",
    "    r = requests.get('https://raw.githubusercontent.com/' + organization_name + '/' + repo_name + '/master/' + path)\n",
    "    file_text = r.text.split('\\n')\n",
    "    file_rows = csv.DictReader(file_text)\n",
    "    table = []\n",
    "    for row in file_rows:\n",
    "        table.append(row)\n",
    "    return table\n",
    "\n",
    "# write a list of dictionaries to a CSV file using filestream\n",
    "def write_dicts_to_string(table, fieldnames):\n",
    "    output = io.StringIO()\n",
    "    writer = csv.DictWriter(output, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in table:\n",
    "        writer.writerow(row)\n",
    "    return output.getvalue()\n",
    "\n",
    "# LIST OF LISTS FUNCTIONS\n",
    "\n",
    "# read from a CSV file in GitHub into a list of lists (representing a table)\n",
    "def read_lists_from_github_csv(organization_name, repo_name, path_to_directory, filename):\n",
    "    path = path_to_directory + filename\n",
    "    r = requests.get('https://raw.githubusercontent.com/' + organization_name + '/' + repo_name + '/master/' + path)\n",
    "    file_text = r.text.split('\\n')\n",
    "    # remove any trailing newlines\n",
    "    if file_text[len(file_text)-1] == '':\n",
    "        file_text = file_text[0:len(file_text)-1]\n",
    "    file_rows = csv.reader(file_text)\n",
    "    table = []\n",
    "    for row in file_rows:\n",
    "        table.append(row)\n",
    "    return table\n",
    "\n",
    "# write a list of lists to a CSV file on disk\n",
    "def write_lists_to_csv(file_name, array):\n",
    "    with open(file_name, 'w', newline='', encoding='utf-8') as file_object:\n",
    "        writer_object = csv.writer(file_object)\n",
    "        for row in array:\n",
    "            writer_object.writerow(row)\n",
    "\n",
    "# write a list of lists to a CSV file using filestream\n",
    "def write_lists_to_string(table):\n",
    "    output = io.StringIO()\n",
    "    writer = csv.writer(output)\n",
    "    for row in table:\n",
    "        writer.writerow(row)\n",
    "    return output.getvalue()\n",
    "\n",
    "# -----------------\n",
    "# functions for interacting with GitHub\n",
    "# -----------------\n",
    "\n",
    "# value of directory should be either 'home' or 'working'\n",
    "def load_credential(filename, directory):\n",
    "    cred = ''\n",
    "    # to change the script to look for the credential in the working directory, change the value of home to empty string\n",
    "    if directory == 'home':\n",
    "        home = str(Path.home()) #gets path to home directory; supposed to work for Win and Mac\n",
    "        credential_path = home + '/' + filename\n",
    "    else:\n",
    "        directory = 'working'\n",
    "        credential_path = filename\n",
    "    try:\n",
    "        with open(credential_path, 'rt', encoding='utf-8') as file_object:\n",
    "            cred = file_object.read()\n",
    "    except:\n",
    "        print(filename + ' file not found - is it in your ' + directory + ' directory?')\n",
    "        exit()\n",
    "    return(cred)\n",
    "\n",
    "# pass in an empty string for organization_name to use an individual account\n",
    "# pass in an empty string for github_username to use a token instead of username login\n",
    "def login_get_repo(repo_name, github_username, organization_name, organization_is_user, cred_directory):\n",
    "    if github_username == '':\n",
    "        token = load_credential('linked-data_github_token.txt', cred_directory)\n",
    "        g = Github(login_or_token = token)\n",
    "    else:\n",
    "        pwd = load_credential('pwd.txt', cred_directory)\n",
    "        g = Github(github_username, pwd)\n",
    "    \n",
    "    if organization_is_user:\n",
    "        # this option accesses a user's repo instead of an organizational one\n",
    "        # In this case, the value of organization_name is not used.\n",
    "        user = g.get_user()\n",
    "        repo = user.get_repo(repo_name)\n",
    "    else:\n",
    "        # this option creates an instance of a repo in an organization\n",
    "        # to which the token creator has push access\n",
    "        organization = g.get_organization(organization_name)\n",
    "        repo = organization.get_repo(repo_name)\n",
    "    return(repo)\n",
    "\n",
    "def get_user_list(repo):\n",
    "    person_list = []\n",
    "    people = repo.get_collaborators()\n",
    "    for person in people:\n",
    "        person_list.append(person.login)\n",
    "    return person_list\n",
    "\n",
    "def get_file_sha(account, repo, file_path):\n",
    "    # get the data about the file to get its blob SHA\n",
    "\n",
    "    r = requests.get('https://api.github.com/repos/' + account + '/' + repo + '/contents/' + file_path)\n",
    "    file_data = r.json()\n",
    "    try:\n",
    "        sha = file_data['sha']\n",
    "    except:\n",
    "        # if the file doesn't already exist on GitHub, no sha will be returned\n",
    "        sha = ''\n",
    "    return sha\n",
    "\n",
    "# use this function to update an existing text file\n",
    "def update_file(repo, account, repo_name, path_to_directory, filename, content):\n",
    "    path = path_to_directory + filename\n",
    "    commit_message = 'Update ' + filename + ' file via API'\n",
    "    sha = get_file_sha(account, repo_name, path)\n",
    "    if sha == '':\n",
    "        response = repo.create_file(path, commit_message, content)\n",
    "    else:\n",
    "        response = repo.update_file(path, commit_message, content, sha)\n",
    "    return response\n",
    "\n",
    "# -----------------\n",
    "# functions for interacting with the YouTube Analytics API (not the Data API)\n",
    "# -----------------\n",
    "\n",
    "# See sample code at https://developers.google.com/youtube/analytics/reference/reports/query#python\n",
    "# That's the source of these functions (with some minor modifications)\n",
    "\n",
    "def get_service():\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, scopes)\n",
    "    credentials = flow.run_console()\n",
    "    return build(api_service_name, api_version, credentials = credentials)\n",
    "\n",
    "def execute_api_request(client_library_function, **kwargs):\n",
    "    response = client_library_function(\n",
    "        **kwargs\n",
    "        ).execute()\n",
    "    return response\n",
    "    \n",
    "# -----------------\n",
    "# High level functions\n",
    "# -----------------\n",
    "\n",
    "# Loads video data and builds the filter string from video IDs.\n",
    "# Note: the video filter can send up to 500 IDs. \n",
    "# As of 2021-02-02, I have 268 videos I'm tracking, so at some point, \n",
    "# this may have to be broken into two or more API calls.\n",
    "# Load data about videos to monitor.\n",
    "def built_video_filter_string(video_metadata_filename):\n",
    "    metadata = read_dicts_from_github_csv(organization_name, repo_name, path_to_directory, video_metadata_filename)\n",
    "    filter_string = 'video=='\n",
    "    output_header_list = ['date']\n",
    "    count = 0\n",
    "    for video in metadata:\n",
    "    #for video in metadata[0:5]: # switch to this line for testing\n",
    "        count += 1\n",
    "        if count > 500:\n",
    "            print('Warning: limit of 500 videos exceeded! Modify the script.')\n",
    "            break\n",
    "        filter_string += video['id'].strip() + ','\n",
    "        output_header_list.append(video['id'].strip())\n",
    "    # remove final trailing comma\n",
    "    filter_string = filter_string[:len(filter_string)-1]\n",
    "    return filter_string, output_header_list\n",
    "\n",
    "def get_youtube_usage_stats(todays_date_utc, filter_string):\n",
    "    print('sending request to YouTube Analytics API')\n",
    "    result = execute_api_request(\n",
    "        youtubeAnalytics.reports().query,\n",
    "        ids='channel==MINE',\n",
    "        startDate='2013-01-01', # don't have any videos dated earlier than that\n",
    "        endDate=todays_date_utc,\n",
    "        metrics='estimatedMinutesWatched,views',\n",
    "        filters=filter_string,\n",
    "        dimensions='video'\n",
    "        )\n",
    "    #print(json.dumps(result, indent=2))\n",
    "    print('done retrieving data from YouTube API')\n",
    "    return result\n",
    "\n",
    "# This retrieves data for counts and minutes, then appends the results as a new row in the table.\n",
    "# The revised tables are then pushed to GitHub\n",
    "# The first column must be the date.\n",
    "def add_data_to_tables():\n",
    "    todays_date_utc = generate_utc_date()\n",
    "    filter_string, output_header_list = built_video_filter_string('video-metadata.csv')\n",
    "    \n",
    "    minutes_table = read_lists_from_github_csv(organization_name, repo_name, path_to_directory, 'total_minutes_watched.csv')\n",
    "    views_table = read_lists_from_github_csv(organization_name, repo_name, path_to_directory, 'total_views.csv')\n",
    "\n",
    "    # Check to make sure that there are the same number of videos in the metadata list and the tables\n",
    "    # If not, nothing happens\n",
    "    if len(minutes_table[0]) != len(output_header_list):\n",
    "        print('minutes table:', len(minutes_table[0]), ' header list:', len(output_header_list))\n",
    "        print('Warning! Minutes table does not have the same number of videos as the videos metadata table!')\n",
    "        return\n",
    "    \n",
    "    if len(views_table[0]) != len(output_header_list):\n",
    "        print('views table:', len(views_table[0]), ' header list:', len(output_header_list))\n",
    "        print('Warning! Views table does not have the same number of videos as the videos metadata table!')\n",
    "        return\n",
    "    \n",
    "    tries = 0\n",
    "    success = False\n",
    "\n",
    "    # try to acquire the data for an hour\n",
    "    while (success == False) and (tries < 12):\n",
    "        try:\n",
    "            results = get_youtube_usage_stats(todays_date_utc, filter_string)\n",
    "            api_data = results['rows']\n",
    "            #print(api_data)\n",
    "\n",
    "            #dictionary = get_unit_counts(query)\n",
    "            success = True\n",
    "            \n",
    "            # We start the new row with the date (first column)\n",
    "            minutes_row = [todays_date_utc]\n",
    "            views_row = [todays_date_utc]\n",
    "\n",
    "            # The video IDs from the API data are compared with the column headers from the minutes table.\n",
    "            # We are assuming that all videos in the video metadata table are found in the column headers.\n",
    "            for header in output_header_list[1:]: # skip the first item (date)\n",
    "                found = False\n",
    "                \n",
    "                # Step through the API records and match with the header\n",
    "                for video in api_data:\n",
    "                    if video[0] == header:\n",
    "                        found = True\n",
    "                        minutes_row.append(str(video[1]))\n",
    "                        views_row.append(str(video[2]))\n",
    "                        break\n",
    "                # In the case where the videos metadata table has a video not in the API results, it's added as a blank cell\n",
    "                if not found:\n",
    "                    minutes_row.append('0')\n",
    "                    views_row.append('0')\n",
    "        except:\n",
    "            tries += 1\n",
    "            sleep(300) # wait 5 minutes and try again\n",
    "\n",
    "    if success:\n",
    "        # log into the GitHub API and create a repo instance\n",
    "        repo = login_get_repo(repo_name, github_username, organization_name, organization_is_user, cred_directory)\n",
    "        \n",
    "        minutes_table.append(minutes_row)\n",
    "        rawCsvText = write_lists_to_string(minutes_table)\n",
    "        response = update_file(repo, organization_name, repo_name, path_to_directory, 'total_minutes_watched.csv', rawCsvText)\n",
    "        print('minutes response: ')\n",
    "        print(response)\n",
    "\n",
    "        views_table.append(views_row)\n",
    "        rawCsvText = write_lists_to_string(views_table)\n",
    "        response = update_file(repo, organization_name, repo_name, path_to_directory, 'total_views.csv', rawCsvText)\n",
    "        print('views response: ')\n",
    "        print(response)\n",
    "\n",
    "        # Update the date last run\n",
    "        response = update_file(repo, organization_name, repo_name, path_to_directory, 'last_run.txt', generate_utc_date() )\n",
    "        print('done')\n",
    "\n",
    "        #write_lists_to_csv('total_minutes_watched_test.csv', minutes_table)\n",
    "        #write_lists_to_csv('total_views_test.csv', views_table)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line performs the YouTube Analytics API authentication. Run it once at the start of the session. Not sure how long the session lasts but it could be something like 30 days?\n",
    "\n",
    "After running this cell, be sure to clear the cell output before pushing the notebook file to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication done: 2021-02-04T03:09:02.689449\n",
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1058294683545-gadov8jftptq5d02rdevgkmv0dtu3ro9.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyt-analytics.readonly&state=2wuYJr8gUtOt5juE5fmm132JgzXZ3e&prompt=consent&access_type=offline\n",
      "Enter the authorization code: 4/1AY0e-g4ISpORjEood8FtESIFiY1nS6j6iODBKdpR9TU23wfLdcvX2Ay56is\n"
     ]
    }
   ],
   "source": [
    "print('Authentication done:', datetime.datetime.utcnow().isoformat())\n",
    "youtubeAnalytics = get_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time checked: 2021-02-04T03:09:30.150553\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T04:09:31.263987\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T07:05:06.406902\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T08:05:06.796864\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T09:05:07.158733\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T10:05:07.514928\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T11:05:07.958905\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T12:05:08.306589\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T13:05:09.200449\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T14:05:09.725736\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T15:05:10.247493\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T16:05:10.849095\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T17:05:11.398246\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T18:05:12.508844\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T19:05:13.060828\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T20:05:13.539008\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T21:05:14.018749\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T22:05:14.527948\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-04T23:05:15.075321\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-04\n",
      "\n",
      "Time checked: 2021-02-05T00:05:15.587207\n",
      "Date last run: 2021-02-04\n",
      "UTC date now is: 2021-02-05\n",
      "sending request to YouTube Analytics API\n",
      "done retrieving data from YouTube API\n",
      "minutes response: \n",
      "{'commit': Commit(sha=\"ed20071d8aa0f3e82464586e4eca79c0b628b738\"), 'content': ContentFile(path=\"disc/youtube/total_minutes_watched.csv\")}\n",
      "views response: \n",
      "{'commit': Commit(sha=\"048869fbe62b8855a2169e7c101e09754b869326\"), 'content': ContentFile(path=\"disc/youtube/total_views.csv\")}\n",
      "done\n",
      "\n",
      "Time checked: 2021-02-05T01:05:21.831598\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T02:05:22.317082\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T03:05:22.721658\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T04:05:23.330965\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T11:41:10.517278\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T12:41:10.937021\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T13:46:57.419141\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T14:46:57.954223\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T15:46:58.554150\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T16:46:59.041704\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T17:46:59.567613\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T18:47:00.231465\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T19:47:00.771910\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T20:47:01.328891\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T21:55:51.465758\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T22:55:52.158312\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-05T23:55:52.638253\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-05\n",
      "\n",
      "Time checked: 2021-02-06T00:55:53.232167\n",
      "Date last run: 2021-02-05\n",
      "UTC date now is: 2021-02-06\n",
      "sending request to YouTube Analytics API\n",
      "done retrieving data from YouTube API\n",
      "minutes response: \n",
      "{'commit': Commit(sha=\"ba4196b3d2f841a2be4b4d32874387d108961dd6\"), 'content': ContentFile(path=\"disc/youtube/total_minutes_watched.csv\")}\n",
      "views response: \n",
      "{'commit': Commit(sha=\"63a5c80097ca5f2a808781a508d5f426201fa5d8\"), 'content': ContentFile(path=\"disc/youtube/total_views.csv\")}\n",
      "done\n",
      "\n",
      "Time checked: 2021-02-06T01:55:59.442046\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T02:55:59.955079\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T03:56:00.547303\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T04:56:01.098174\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T05:56:01.546604\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T06:56:02.013670\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T07:56:02.396100\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T08:56:02.728142\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T09:56:03.115231\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T10:56:03.457382\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T11:56:03.899245\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T12:56:04.208955\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T13:56:04.614375\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T14:56:05.149486\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T15:56:05.975322\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T16:56:06.534959\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T17:56:07.013023\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T18:56:07.494331\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T19:56:09.063033\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T20:56:09.491471\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T21:56:10.028020\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T22:56:10.517322\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-06T23:56:10.944404\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-06\n",
      "\n",
      "Time checked: 2021-02-07T00:56:11.568702\n",
      "Date last run: 2021-02-06\n",
      "UTC date now is: 2021-02-07\n",
      "sending request to YouTube Analytics API\n",
      "done retrieving data from YouTube API\n",
      "minutes response: \n",
      "{'commit': Commit(sha=\"e1c241425ded061a2e9cf601f536b2a345c6f4df\"), 'content': ContentFile(path=\"disc/youtube/total_minutes_watched.csv\")}\n",
      "views response: \n",
      "{'commit': Commit(sha=\"e3919a3845fe4a81a97fc67edb37e32ce5948ce6\"), 'content': ContentFile(path=\"disc/youtube/total_views.csv\")}\n",
      "done\n",
      "\n",
      "Time checked: 2021-02-07T01:56:17.644166\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T02:56:18.169542\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T03:56:18.686328\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T04:56:19.178354\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T05:56:19.636130\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T06:56:20.060187\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T07:56:20.627981\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T08:56:20.974396\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T09:56:21.286304\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T10:56:21.689563\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T11:56:22.125257\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T12:56:22.462380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred, trying again in 10 minutes\n",
      "ConnectionError (MaxRetryError(\"HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /heardlibrary/dashboard/master/disc/youtube/last_run.txt (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fae20a17cf8>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\"),)\n",
      "Time checked: 2021-02-07T13:06:23.588015\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T14:06:23.968257\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T15:06:24.480826\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T16:06:25.055233\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T17:06:25.530549\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T18:06:25.975442\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T19:06:26.486406\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T20:06:27.075795\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T21:06:27.608100\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T22:06:28.147906\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-07T23:06:28.541094\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-07\n",
      "\n",
      "Time checked: 2021-02-08T00:06:29.047910\n",
      "Date last run: 2021-02-07\n",
      "UTC date now is: 2021-02-08\n",
      "sending request to YouTube Analytics API\n",
      "done retrieving data from YouTube API\n",
      "minutes response: \n",
      "{'commit': Commit(sha=\"ba0b494ddf19ac56baa37accc1e6f6fbcc3015d0\"), 'content': ContentFile(path=\"disc/youtube/total_minutes_watched.csv\")}\n",
      "views response: \n",
      "{'commit': Commit(sha=\"5962b39a02443a7c9af1a820c9b6eef5f03defb6\"), 'content': ContentFile(path=\"disc/youtube/total_views.csv\")}\n",
      "done\n",
      "\n",
      "Time checked: 2021-02-08T01:06:36.162716\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T02:06:36.672736\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T03:06:37.315502\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T04:06:37.793582\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T11:25:27.094896\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T12:25:27.572567\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T13:25:28.693969\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T14:25:29.203020\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T15:25:29.694533\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T16:25:30.296369\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T17:25:30.840817\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T18:25:31.387338\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T19:25:32.032437\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T20:25:32.527418\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T21:25:32.955514\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T22:25:33.596846\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-08T23:25:34.219715\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-08\n",
      "\n",
      "Time checked: 2021-02-09T00:25:34.989320\n",
      "Date last run: 2021-02-08\n",
      "UTC date now is: 2021-02-09\n",
      "sending request to YouTube Analytics API\n",
      "done retrieving data from YouTube API\n",
      "minutes response: \n",
      "{'commit': Commit(sha=\"ffb4a210409e7490c99b22e31d3933bd6b06d152\"), 'content': ContentFile(path=\"disc/youtube/total_minutes_watched.csv\")}\n",
      "views response: \n",
      "{'commit': Commit(sha=\"0e97d0aa374249732045fa1457d592c69e5db1c8\"), 'content': ContentFile(path=\"disc/youtube/total_views.csv\")}\n",
      "done\n",
      "\n",
      "Time checked: 2021-02-09T01:25:41.867068\n",
      "Date last run: 2021-02-09\n",
      "UTC date now is: 2021-02-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True: # infinite loop\n",
    "    try:\n",
    "        print('Time checked:', datetime.datetime.utcnow().isoformat())\n",
    "\n",
    "        date_last_run = read_string_from_github_file(organization_name, repo_name, path_to_directory, 'last_run.txt')\n",
    "        print('Date last run:', date_last_run)\n",
    "\n",
    "        date_now_utc = generate_utc_date()\n",
    "        print('UTC date now is:', date_now_utc)\n",
    "\n",
    "        if date_now_utc > date_last_run:\n",
    "            add_data_to_tables()\n",
    "        print()\n",
    "        # wait an hour before checking again\n",
    "        sleep(3600)\n",
    "    except Exception as ex:\n",
    "        print('Error occurred, trying again in 10 minutes')\n",
    "        print(type(ex).__name__, ex.args)\n",
    "        sleep(600)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
